{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "!mkdir -p /root/.config/kaggle\n",
        "!sudo cp kaggle.json ~/.config/kaggle/\n",
        "!sudo chmod 600 ~/.config/kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "CdTY_LrPh0M1"
      },
      "id": "CdTY_LrPh0M1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision segmentation-models-pytorch albumentations opencv-python"
      ],
      "metadata": {
        "id": "LKZ81Iz4I64n"
      },
      "id": "LKZ81Iz4I64n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "metadata": {
        "id": "vuBUmzPZI-Kx"
      },
      "id": "vuBUmzPZI-Kx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d tapakah68/segmentation-full-body-mads-dataset\n",
        "!unzip segmentation-full-body-mads-dataset.zip"
      ],
      "metadata": {
        "id": "vXHNx27WJrp1"
      },
      "id": "vXHNx27WJrp1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UNet"
      ],
      "metadata": {
        "id": "ZCvgjj7F-Ngo"
      },
      "id": "ZCvgjj7F-Ngo"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            # dropout\n",
        "            nn.Dropout2d(0.2),\n",
        "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.down1 = DoubleConv(in_channels, 64)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.down2 = DoubleConv(64, 128)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.down3 = DoubleConv(128, 256)\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.down4 = DoubleConv(256, 512)\n",
        "        self.pool4 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.bottleneck = DoubleConv(512, 1024)\n",
        "\n",
        "        self.up4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
        "        self.dec4 = DoubleConv(1024, 512)\n",
        "\n",
        "        self.up3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
        "        self.dec3 = DoubleConv(512, 256)\n",
        "\n",
        "        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "        self.dec2 = DoubleConv(256, 128)\n",
        "\n",
        "        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.dec1 = DoubleConv(128, 64)\n",
        "\n",
        "        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        d1 = self.down1(x)\n",
        "        d2 = self.down2(self.pool1(d1))\n",
        "        d3 = self.down3(self.pool2(d2))\n",
        "        d4 = self.down4(self.pool3(d3))\n",
        "\n",
        "        bn = self.bottleneck(self.pool4(d4))\n",
        "\n",
        "        up4 = self.up4(bn)\n",
        "        up4 = torch.cat([up4, d4], dim=1)\n",
        "        dec4 = self.dec4(up4)\n",
        "\n",
        "        up3 = self.up3(dec4)\n",
        "        up3 = torch.cat([up3, d3], dim=1)\n",
        "        dec3 = self.dec3(up3)\n",
        "\n",
        "        up2 = self.up2(dec3)\n",
        "        up2 = torch.cat([up2, d2], dim=1)\n",
        "        dec2 = self.dec2(up2)\n",
        "\n",
        "        up1 = self.up1(dec2)\n",
        "        up1 = torch.cat([up1, d1], dim=1)\n",
        "        dec1 = self.dec1(up1)\n",
        "\n",
        "        return self.final_conv(dec1)\n"
      ],
      "metadata": {
        "id": "rdZVPPl6B8Mr"
      },
      "execution_count": null,
      "outputs": [],
      "id": "rdZVPPl6B8Mr"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import cv2\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# Paths\n",
        "image_dir = './segmentation_full_body_mads_dataset_1192_img/segmentation_full_body_mads_dataset_1192_img/images'\n",
        "mask_dir = './segmentation_full_body_mads_dataset_1192_img/segmentation_full_body_mads_dataset_1192_img/masks'\n",
        "\n",
        "# -------- Dataset -------- #\n",
        "\n",
        "class SegmentationDataset(Dataset):\n",
        "    def __init__(self, image_paths, mask_paths, transforms=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.mask_paths = mask_paths\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = cv2.imread(self.image_paths[idx])           # BGR image\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)      # Convert to RGB\n",
        "        mask = cv2.imread(self.mask_paths[idx], cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        mask = (mask > 127).astype(np.float32)\n",
        "        # print(\"mask unique values:\", np.unique(mask))\n",
        "\n",
        "\n",
        "        if self.transforms:\n",
        "            augmented = self.transforms(image=image, mask=mask)\n",
        "            image = augmented['image']\n",
        "            mask = augmented['mask'].unsqueeze(0)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "# -------- Transforms -------- #\n",
        "train_transform = A.Compose([\n",
        "    A.Resize(256, 256),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.Normalize(),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "val_transform = A.Compose([\n",
        "    A.Resize(256, 256),\n",
        "    A.Normalize(),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "# -------- Data Split -------- #\n",
        "image_files = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir)])\n",
        "mask_files = sorted([os.path.join(mask_dir, f) for f in os.listdir(mask_dir)])\n",
        "\n",
        "train_imgs, val_imgs, train_masks, val_masks = train_test_split(\n",
        "    image_files, mask_files, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "train_dataset = SegmentationDataset(train_imgs, train_masks, transforms=train_transform)\n",
        "val_dataset = SegmentationDataset(val_imgs, val_masks, transforms=val_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, num_workers=4, pin_memory=True)\n",
        "\n",
        "\n",
        "# -------- Model -------- #\n",
        "model = UNet()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# -------- Loss & Optimizer -------- #\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# -------- IoU Metric -------- #\n",
        "def iou_score(preds, targets, threshold=0.5):\n",
        "    # print(\"preds shape:\", preds.shape)\n",
        "    # print(\"targets shape:\", targets.shape)\n",
        "    # predicted_mask = torch.sigmoid(preds) > threshold\n",
        "    predicted_mask = preds > threshold\n",
        "    predicted_mask = predicted_mask.bool()\n",
        "    true_mask = targets.bool()\n",
        "    intersection = (predicted_mask & true_mask).sum(dim=(1, 2, 3))\n",
        "    union = (predicted_mask | true_mask).sum(dim=(1, 2, 3))\n",
        "    iou = (intersection + 1e-6) / (union + 1e-6)\n",
        "    return iou.mean().item()\n",
        "\n",
        "\n",
        "# -------- Training Loop -------- #\n",
        "scaler = GradScaler()\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for imgs, masks in tqdm(loader, desc=\"Training\"):\n",
        "        imgs, masks = imgs.to(device, non_blocking=True), masks.to(device, non_blocking=True)\n",
        "        optimizer.zero_grad()\n",
        "        with autocast():\n",
        "            preds = model(imgs)\n",
        "            loss = criterion(preds, masks)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    total_iou = 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, masks in loader:\n",
        "            imgs, masks = imgs.to(device, non_blocking=True), masks.to(device, non_blocking=True)\n",
        "            preds = model(imgs)\n",
        "            preds = torch.sigmoid(preds)  # Apply sigmoid once here\n",
        "            total_iou += iou_score(preds, masks)\n",
        "    return total_iou / len(loader)\n",
        "\n",
        "# -------- Run Training -------- #\n",
        "epochs = 25\n",
        "train_losses = []\n",
        "val_ious = []\n",
        "for epoch in range(epochs):\n",
        "    print(\"starting to train\")\n",
        "    train_loss = train_one_epoch(model, train_loader, optimizer, criterion)\n",
        "    val_iou = evaluate(model, val_loader)\n",
        "    train_losses.append(train_loss)\n",
        "    val_ious.append(val_iou)\n",
        "    print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Val IoU: {val_iou:.4f}\")\n"
      ],
      "metadata": {
        "id": "Umy2UOVl-60a"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Umy2UOVl-60a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet"
      ],
      "metadata": {
        "id": "RjK6nj5-YOaN"
      },
      "id": "RjK6nj5-YOaN"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import segmentation_models_pytorch as smp\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "\n",
        "# -------- Model -------- #\n",
        "model = smp.Unet(\n",
        "    encoder_name=\"resnet34\",\n",
        "    encoder_weights=\"imagenet\",\n",
        "    in_channels=3,\n",
        "    classes=1,\n",
        "    activation=None  # We'll apply sigmoid manually\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# -------- Loss & Optimizer -------- #\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "\n",
        "\n",
        "# -------- Run Training -------- #\n",
        "epochs = 20\n",
        "train_losses = []\n",
        "val_ious = []\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train_one_epoch(model, train_loader, optimizer, criterion)\n",
        "    val_iou = evaluate(model, val_loader)\n",
        "    train_losses.append(train_loss)\n",
        "    val_ious.append(val_iou)\n",
        "    print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Val IoU: {val_iou:.4f}\")\n"
      ],
      "metadata": {
        "id": "rxN6lmmWMyR2"
      },
      "id": "rxN6lmmWMyR2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zero Shot"
      ],
      "metadata": {
        "id": "lnR13Q1LH9nH"
      },
      "id": "lnR13Q1LH9nH"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U git+https://github.com/luca-medeiros/lang-segment-anything.git"
      ],
      "metadata": {
        "id": "KYppJAvWj7Qp"
      },
      "id": "KYppJAvWj7Qp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from lang_sam import LangSAM\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import kaggle\n",
        "import cv2\n",
        "\n",
        "model = LangSAM()\n",
        "text_prompt = \"person.\""
      ],
      "metadata": {
        "id": "Fgodmg9rkNeg"
      },
      "id": "Fgodmg9rkNeg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def intersection_over_union_metric(predicted_mask, true_mask):\n",
        "    predicted_mask = predicted_mask.astype(bool)\n",
        "    true_mask = true_mask.astype(bool)\n",
        "    intersection = np.logical_and(predicted_mask, true_mask).sum()\n",
        "    union = np.logical_or(predicted_mask, true_mask).sum()\n",
        "    if union == 0:\n",
        "        return 0.0\n",
        "    iou = intersection / union\n",
        "    return iou"
      ],
      "metadata": {
        "id": "nHE9z-cvnGfq"
      },
      "id": "nHE9z-cvnGfq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model_on_test_set(test_images_dir='./test_images',\n",
        "                                test_masks_dir='./test_masks',\n",
        "                                text_prompt=\"person.\",\n",
        "                                evaluation_function=intersection_over_union_metric\n",
        "                                ):\n",
        "    iou_results = []\n",
        "\n",
        "    # Ensure the directories exist\n",
        "    if not os.path.exists(test_images_dir):\n",
        "        print(f\"Test images directory not found: {test_images_dir}\")\n",
        "    elif not os.path.exists(test_masks_dir):\n",
        "        print(f\"Test masks directory not found: {test_masks_dir}\")\n",
        "    else:\n",
        "        image_files = [f for f in os.listdir(test_images_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "        for image_file in image_files:\n",
        "            image_path = os.path.join(test_images_dir, image_file)\n",
        "            mask_file = image_file # Assuming the mask file has the same name as the image file\n",
        "            mask_path = os.path.join(test_masks_dir, mask_file)\n",
        "\n",
        "            if not os.path.exists(mask_path):\n",
        "                print(f\"Ground truth mask not found for {image_file}\")\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "              # Load the image\n",
        "              image_pil = Image.open(image_path).convert(\"RGB\")\n",
        "              image_np = np.array(image_pil)\n",
        "\n",
        "              # Load the ground truth mask\n",
        "              # Assuming the ground truth mask is a grayscale image where the wound is white (255) and background is black (0)\n",
        "              true_mask_pil = Image.open(mask_path).convert(\"L\")\n",
        "              true_mask_np = np.array(true_mask_pil) > 0 # Convert to boolean mask\n",
        "              # Predict the mask using LangSAM\n",
        "              # LangSAM expects a list of images and a list of prompts\n",
        "              result = model.predict([image_pil], [text_prompt])\n",
        "              scores = result[0]['scores'] # float array\n",
        "              boxes = result[0]['boxes']\n",
        "              masks = result[0]['masks']\n",
        "              masks_scores = result[0]['mask_scores'] # float array\n",
        "\n",
        "              if len(masks) == 0:\n",
        "                  print(f\"No Prediction found for {image_file}\")\n",
        "                  iou_results.append({'image': image_file, 'iou': np.nan})\n",
        "                  continue\n",
        "\n",
        "              if masks is not None and not(isinstance(masks, list)):\n",
        "                  if masks_scores.ndim == 0:\n",
        "                      masks_scores = [masks_scores.item()]\n",
        "                  if scores.ndim == 0:\n",
        "                      scores = [scores.item()]\n",
        "\n",
        "                  # LangSAM masks are shape [num_masks, H, W]\n",
        "                  max_index = 0\n",
        "                  for i, predicted_mask in enumerate(masks):\n",
        "                      # find the mask that has the highest score\n",
        "                      if masks_scores[max_index] < masks_scores[i]:\n",
        "                        if scores[max_index] < scores[i]:\n",
        "                          max_index = i\n",
        "\n",
        "                  predicted_mask_np = masks[max_index]\n",
        "                  result_iou = evaluation_function(predicted_mask_np, true_mask_np)\n",
        "\n",
        "              iou_results.append({'image': image_file, 'iou': result_iou})\n",
        "              print(f\"Processed {image_file}, IoU: {result_iou:.4f}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {image_file}: {e}\")\n",
        "                iou_results.append({'image': image_file, 'iou': np.nan}) # Append NaN for errors\n",
        "\n",
        "    # Print average IoU\n",
        "    if len(iou_results) > 0:\n",
        "        average_iou = np.nanmean([res['iou'] for res in iou_results])\n",
        "        print(f\"\\nAverage IoU across test set: {average_iou:.4f}\")\n",
        "    else:\n",
        "        print(\"No images were processed.\")\n",
        "\n",
        "    return iou_results\n"
      ],
      "metadata": {
        "id": "41iLCJgKKfVh"
      },
      "id": "41iLCJgKKfVh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images_dir = './segmentation_full_body_mads_dataset_1192_img/segmentation_full_body_mads_dataset_1192_img/images'\n",
        "test_masks_dir = './segmentation_full_body_mads_dataset_1192_img/segmentation_full_body_mads_dataset_1192_img/masks'\n",
        "text_prompt = \"person.\"\n",
        "\n",
        "iou_results = evaluate_model_on_test_set(test_images_dir, test_masks_dir, text_prompt, intersection_over_union_metric)\n"
      ],
      "metadata": {
        "id": "ru5p1w9FK09I"
      },
      "id": "ru5p1w9FK09I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the iou_results by IoU in ascending order\n",
        "sorted_iou_results = sorted(iou_results, key=lambda x: x['iou'])\n",
        "\n",
        "# Get the lowest values and their corresponding image names\n",
        "lowest_iou_results = sorted_iou_results[:20] # Get the bottom 10\n",
        "\n",
        "print(\"Lowest IoU values and corresponding image names:\")\n",
        "for result in lowest_iou_results:\n",
        "  print(f\"Image: {result['image']}, IoU: {result['iou']:.4f}\")"
      ],
      "metadata": {
        "id": "9sWDjvCLEveo"
      },
      "id": "9sWDjvCLEveo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iou_scores = [res['iou'] for res in iou_results if not np.isnan(res['iou'])]\n",
        "\n",
        "if len(iou_scores) >= 0:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(iou_scores, bins=25, edgecolor='black')\n",
        "    plt.title('Distribution of IoU Scores on Test Set')\n",
        "    plt.xlabel('IoU Score')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.grid(axis='y', alpha=0.75)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No valid IoU scores available to plot the histogram.\")"
      ],
      "metadata": {
        "id": "aJ_msGuP3I90"
      },
      "id": "aJ_msGuP3I90",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute average IoU\n",
        "if len(iou_results) > 0:\n",
        "    # Filter out NaN values before computing the mean\n",
        "    valid_ious = [res['iou'] for res in iou_results if not np.isnan(res['iou'])]\n",
        "    if len(valid_ious) > 0:\n",
        "        average_iou = np.mean(valid_ious)\n",
        "        print(f\"\\nAverage IoU across test set: {average_iou:.4f}\")\n",
        "    else:\n",
        "        print(\"No valid IoU results were computed.\")\n",
        "else:\n",
        "    print(\"No images were processed.\")\n"
      ],
      "metadata": {
        "id": "BB-cm_Ig1Lp7"
      },
      "id": "BB-cm_Ig1Lp7",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
